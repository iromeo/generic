
__default__:
  system: "{{cookiecutter.cluster_system}}" #check if system is defined below

  # default parameter for all rules
  # for steps, where memory/threads are not specified in the Snakefile

  group: "{{cookiecutter.default_job_group}}"
  user_group: "{{cookiecutter.default_user_group}}"
  queue: "{{cookiecutter.default_queue}}"
  docker: "{{cookiecutter.default_docker}}" # e.g. "ubuntu:latest"
  email: "{{cookiecutter.default_email}}"
  #account: ""
  time: "{{cookiecutter.default_time_min}}" # minutes
  vmem: "{{cookiecutter.default_mem_GB}}" # GB, max process virtual memory
  mem_ram: "{{cookiecutter.default_mem_GB}}" # GB, max RAM
  threads: "{{cookiecutter.default_threads}}" # slots number, e.g. could be on different hosts
  job_workdir: "{{cookiecutter.default_job_custom_workdir}}" # job working directory, if not specified defaults will be used

  # Hosts number, e.g. 6 threads could be on the same host if `nodes:1` or split in 2 hosts
  # (e.g. 5+1 or 4+2 or 3+3) if `nodes:2`
  nodes: 1

# Comma separated options keys list from rule 'params' section which could override default option
# values
#  rule_params_options: "queue, account, sampleid"

# only parameters defined in key_mapping (see below) are passed to the command in the order specified.
  command_options:
    # --------- SLURM ---------
    slurm:
      command: "{{cookiecutter.submission_command_prefix}} sbatch --parsable"
      key_mapping:
        # TODO: workdir
        name: " --job-name={name}"
        threads: " -n {threads}"
        vmem: " --mem={vmem}g"
        #mem_ram: " --mem={mem_ram}g"
        account: " --account={account}"
        queue: " --partition={queue}"
        time: " --time={time}"
        nodes: " -N {nodes}"

    # --------- PBS ---------
    pbs:
      command: "{{cookiecutter.submission_command_prefix}} qsub"
      key_mapping:
        job_workdir: " -d {job_workdir}"
        name: " -N sj{jobid}.{name}.{pid}"
        queue: " -q {queue}"

        nodes: " -l nodes={nodes}" # -l has to be on first resource element
        threads: ":ppn={threads},"
        vmem: "vmem={vmem}gb,"
        mem_ram: "mem={mem_ram}gb,"
        time: "walltime={time}:00" # minutes [[HH:]MM:]SS

        merge_std: " -j oe" # merge stdout, stderr
        log: " -o {log}_job.log"

    # --------- LSF ---------
    lsf:
      # command prefix, normally just "bsub", as for suffix, see 'jobscript' in key_mapping
      command: "{{cookiecutter.submission_command_prefix}} bsub"
      # examples:
      #   command: "bsub"
      #   command: "cd $HOME && bsub"

      key_mapping:
        job_workdir: " -cwd {job_workdir}"
        resources: " -R 'select[mem>{mem_ram}000] rusage[mem={mem_ram}000] span[hosts={nodes}]'" # `mem` in mb, `mem_ram` in GB
        #resources: " -R 'select[mem>{mem_ram}000,swp>{vmem}000] rusage[mem={mem_ram}000,swp={vmem}000]'" # mem + swap requirement
        name: " -J sj{jobid}.{name}.{pid}"
        queue: " -q {queue}"
        threads: " -n {threads}"
        #vmem: " -v {vmem}000000"  # swap space (virtual memory) kb value, 'mem' is in gb, by default usually no limit
        mem_ram: " -M {mem_ram}000"  # ram mem MB value, 'mem_ram' is in gb
        time: " -W {time}"  # time in minutes, -W [hour:]minute
        log: " -oo {log}_job.log" # rewrite log file, send stderr and stdout to log
        group: " -g {group}"
        user_group: " -G {user_group}"
        email: " -N -u {email}"
        docker: "  -a 'docker({docker})'"
        account: " -P {account}"
        # normally should be last argument, {jobscript} is value provided by the scheduler, you could wrap it here
        # E.g. " /bin/bash -c 'source /opt/conda/.bashrc && {jobscript}'"
        jobscript: " {jobscript}"

# --------- Other ---------
# for other cluster systems see: https://slurm.schedmd.com/rosetta.pdf

# --------- Rule Specific ---------
# specific parameters for certain rules, which need more time/memory

#run_assembler:
#  queue: bigmem
#  time: 1710
#   threads and memory definen in config file
